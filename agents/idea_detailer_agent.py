"""
æƒ³æ³•è¯¦ç»†åŒ–Agent
è´Ÿè´£å°†æœ€ä¼˜æƒ³æ³•ç»“åˆç›¸å…³è®ºæ–‡è¿›è¡Œè¯¦ç»†åŒ–
"""

from typing import Dict, Optional, List
import json
from pathlib import Path

from agents.base_agent import BaseAgent
from agents.idea_selector_agent import IdeaSelectorAgent
from utils.api_client import UnifiedLLMClient


class IdeaDetailerAgent(BaseAgent):
    """æƒ³æ³•è¯¦ç»†åŒ–Agent - å¯é…ç½®ä½¿ç”¨ä¸åŒçš„LLM"""
    
    def __init__(self, api_provider: str = None, model: str = None):
        """
        åˆå§‹åŒ–æƒ³æ³•è¯¦ç»†åŒ–Agent
        
        Args:
            api_provider: APIæä¾›å•†ï¼ŒNoneåˆ™ä»é…ç½®è¯»å–
            model: æ¨¡å‹åç§°ï¼ŒNoneåˆ™ä»é…ç½®è¯»å–
        """
        super().__init__("æƒ³æ³•è¯¦ç»†åŒ–Agent")
        
        # ä»é…ç½®è¯»å–APIè®¾ç½®
        if api_provider is None:
            api_provider = self.config_loader.get('pipeline.idea_detailing.api_provider', 'deepseek')
        if model is None:
            model = self.config_loader.get('pipeline.idea_detailing.model', 'deepseek-chat')
        
        temperature = self.config_loader.get('pipeline.idea_detailing.temperature', 0.7)
        max_tokens = self.config_loader.get('pipeline.idea_detailing.max_tokens', 8192)
        
        self.llm_client = UnifiedLLMClient(
            api_provider=api_provider,
            model=model,
            temperature=temperature,
            max_tokens=max_tokens
        )
        
        self.logger.info(f"ä½¿ç”¨ {api_provider} API, æ¨¡å‹: {model}")
        
        # åˆå§‹åŒ–ç­›é€‰Agent
        self.selector = IdeaSelectorAgent()
    
    def run(self, best_idea: Dict = None, source_papers: Dict = None) -> str:
        """
        è¯¦ç»†åŒ–æœ€ä¼˜æƒ³æ³•
        
        Args:
            best_idea: æœ€ä¼˜æƒ³æ³•ä¿¡æ¯ï¼ŒNoneåˆ™è‡ªåŠ¨ç­›é€‰
            source_papers: ç›¸å…³è®ºæ–‡å†…å®¹ï¼ŒNoneåˆ™è‡ªåŠ¨åŠ è½½
            
        Returns:
            è¯¦ç»†åŒ–åçš„æƒ³æ³•æ–‡æœ¬
        """
        self.log_start("è¯¦ç»†åŒ–æƒ³æ³•")
        
        try:
            # å¦‚æœæœªæä¾›æœ€ä¼˜æƒ³æ³•ï¼Œåˆ™è‡ªåŠ¨ç­›é€‰
            if best_idea is None:
                self.logger.info("è‡ªåŠ¨ç­›é€‰æœ€ä¼˜æƒ³æ³•...")
                best_idea = self.selector.run()
            
            if not best_idea:
                self.logger.warning("æœªæ‰¾åˆ°æœ€ä¼˜æƒ³æ³•")
                return ""
            
            # å¦‚æœæœªæä¾›ç›¸å…³è®ºæ–‡ï¼Œåˆ™è‡ªåŠ¨åŠ è½½ï¼ˆä½¿ç”¨åˆ†æå†…å®¹ï¼‰
            if source_papers is None:
                paper_keys = best_idea.get('source_papers', [])
                self.logger.info(f"åŠ è½½ç›¸å…³è®ºæ–‡çš„åˆ†æ: {paper_keys}")
                source_papers = self._get_source_papers_analysis(paper_keys)
            
            if not source_papers:
                self.logger.warning("æœªæ‰¾åˆ°ç›¸å…³è®ºæ–‡")
                return ""
            
            # æ„å»ºè¾“å…¥æ–‡æœ¬
            input_text = self._format_input_for_llm(source_papers, best_idea)
            
            # è°ƒç”¨LLMè¯¦ç»†åŒ–
            self.logger.info("æ­£åœ¨è¯¦ç»†åŒ–æƒ³æ³•...")
            detailed_idea = self._detail_idea(input_text, len(source_papers))
            
            # ä¿å­˜ç»“æœ
            self.save_result(
                detailed_idea,
                'detailed_idea.md',
                'ideas',
                format='text'
            )
            
            # åŒæ—¶ä¿å­˜JSONæ ¼å¼ï¼ˆåŒ…å«å…ƒæ•°æ®ï¼‰
            result_data = {
                'original_idea': best_idea,
                'source_papers': list(source_papers.keys()),
                'detailed_content': detailed_idea
            }
            self.save_result(
                result_data,
                'detailed_idea.json',
                'ideas',
                format='json'
            )
            
            self.log_end("æƒ³æ³•è¯¦ç»†åŒ–å®Œæˆ")
            return detailed_idea
            
        except Exception as e:
            self.log_error(f"è¯¦ç»†åŒ–æƒ³æ³•å¤±è´¥: {str(e)}")
            raise
    
    def _get_source_papers_analysis(self, paper_keys: List[str]) -> Dict[str, dict]:
        """
        è·å–æŒ‡å®šè®ºæ–‡çš„åˆ†æå†…å®¹ï¼ˆè€Œä¸æ˜¯æ¸…æ´—åçš„å†…å®¹ï¼‰
        
        Args:
            paper_keys: ['paper_1', 'paper_2', ...]
            
        Returns:
            {
                'paper_1': {'name': ..., 'analysis': ...},
                'paper_2': {'name': ..., 'analysis': ...},
                ...
            }
        """
        collection_path = Path("data/collections/all_papers_analyzed.json")
        
        if not collection_path.exists():
            self.logger.warning(f"æœªæ‰¾åˆ°åˆ†æé›†åˆ: {collection_path}")
            return {}
        
        try:
            with open(collection_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            papers = data.get('papers', {})
            
            # æå–æŒ‡å®šçš„è®ºæ–‡
            result = {}
            for paper_key in paper_keys:
                if paper_key in papers:
                    result[paper_key] = {
                        'name': papers[paper_key].get('name', paper_key),
                        'analysis': papers[paper_key].get('analysis', '')
                    }
                    self.logger.info(f"åŠ è½½è®ºæ–‡åˆ†æ: {paper_key} ({result[paper_key]['name']})")
                else:
                    self.logger.warning(f"æœªæ‰¾åˆ°è®ºæ–‡: {paper_key}")
            
            return result
            
        except Exception as e:
            self.log_error(f"åŠ è½½è®ºæ–‡åˆ†æå¤±è´¥: {str(e)}")
            return {}
    
    def _format_input_for_llm(self, source_papers: Dict[str, dict], best_idea: Dict) -> str:
        """
        æ ¼å¼åŒ–è¾“å…¥ç»™LLM
        
        æ ¼å¼:
        ã€Paper_1ã€‘è®ºæ–‡å1ï¼šåˆ†æå†…å®¹...
        ã€Paper_2ã€‘è®ºæ–‡å2ï¼šåˆ†æå†…å®¹...
        ã€Paper_3ã€‘è®ºæ–‡å3ï¼šåˆ†æå†…å®¹...
        
        ã€åŸºäºä»¥ä¸Šæ–‡ç« çš„åˆ›æ–°æƒ³æ³•ã€‘
        æƒ³æ³•å†…å®¹...
        
        Args:
            source_papers: {paper_key: {'name': ..., 'analysis': ...}}
            best_idea: æœ€ä¼˜æƒ³æ³•ä¿¡æ¯
            
        Returns:
            æ ¼å¼åŒ–çš„æ–‡æœ¬
        """
        self.logger.info("=" * 80)
        self.logger.info("ğŸ“ å¼€å§‹æ ¼å¼åŒ–è¾“å…¥ç»™LLM")
        self.logger.info("=" * 80)
        
        formatted_text = ""
        
        # æŒ‰paper_keyæ’åº
        sorted_keys = sorted(source_papers.keys(), 
                           key=lambda x: int(x.split('_')[1]) if '_' in x else 0)
        
        self.logger.info(f"ğŸ“š è®ºæ–‡æ•°é‡: {len(sorted_keys)}")
        self.logger.info(f"ğŸ“š è®ºæ–‡åˆ—è¡¨: {sorted_keys}")
        self.logger.info("")
        
        # æ·»åŠ è®ºæ–‡åˆ†æå†…å®¹ï¼ˆæŒ‰ã€Paper_iã€‘æ ¼å¼ï¼‰
        for paper_key in sorted_keys:
            paper_data = source_papers[paper_key]
            name = paper_data.get('name', paper_key)
            analysis = paper_data.get('analysis', '')
            
            # æå–paperç¼–å·
            paper_num = paper_key.split('_')[1] if '_' in paper_key else '1'
            
            self.logger.info(f"ğŸ“„ æ·»åŠ  Paper_{paper_num}: {name}")
            self.logger.info(f"   åˆ†æå†…å®¹é•¿åº¦: {len(analysis)} å­—ç¬¦")
            self.logger.info(f"   åˆ†æå†…å®¹é¢„è§ˆ: {analysis[:200]}...")
            self.logger.info("")
            
            formatted_text += f"ã€Paper_{paper_num}ã€‘{name}ï¼š\n\n{analysis}\n\n"
            formatted_text += "=" * 80 + "\n\n"
        
        # æ·»åŠ æƒ³æ³•
        idea_content = best_idea.get('full_content', '')
        self.logger.info("ğŸ’¡ æ·»åŠ æœ€ä¼˜æƒ³æ³•")
        self.logger.info(f"   æƒ³æ³•æ ‡é¢˜: {best_idea.get('title', 'N/A')}")
        self.logger.info(f"   æƒ³æ³•è¯„åˆ†: {best_idea.get('score', 'N/A')}")
        self.logger.info(f"   æƒ³æ³•å†…å®¹é•¿åº¦: {len(idea_content)} å­—ç¬¦")
        self.logger.info(f"   æƒ³æ³•å†…å®¹é¢„è§ˆ: {idea_content[:200]}...")
        self.logger.info("")
        
        formatted_text += "ã€åŸºäºä»¥ä¸Šæ–‡ç« çš„åˆ›æ–°æƒ³æ³•ã€‘\n\n"
        formatted_text += idea_content
        
        self.logger.info("=" * 80)
        self.logger.info("ğŸ“Š æ ¼å¼åŒ–å®Œæˆç»Ÿè®¡")
        self.logger.info("=" * 80)
        self.logger.info(f"æ€»å­—ç¬¦æ•°: {len(formatted_text)}")
        self.logger.info(f"æ€»è¡Œæ•°: {formatted_text.count(chr(10))}")
        self.logger.info("")
        self.logger.info("ğŸ“‹ å®Œæ•´è¾“å…¥å†…å®¹é¢„è§ˆï¼ˆå‰500å­—ç¬¦ï¼‰:")
        self.logger.info("-" * 80)
        self.logger.info(formatted_text[:500])
        self.logger.info("-" * 80)
        self.logger.info("")
        
        return formatted_text
    
    def _detail_idea(self, input_text: str, n_papers: int) -> str:
        """
        è°ƒç”¨LLMè¯¦ç»†åŒ–æƒ³æ³•
        
        Args:
            input_text: æ ¼å¼åŒ–çš„è¾“å…¥æ–‡æœ¬
            n_papers: è®ºæ–‡æ•°é‡
            
        Returns:
            è¯¦ç»†åŒ–åçš„æƒ³æ³•
        """
        # æ„å»ºpromptï¼ˆå…ˆè¯´æ˜ä»»åŠ¡ï¼Œå†ç»™å†…å®¹ï¼‰
        prompt = f"""æˆ‘å…ˆç»™ä½ {n_papers}ç¯‡æ–‡ç« ï¼Œç„¶åå†ç»™ä½ æ ¹æ®è¿™{n_papers}ç¯‡æ–‡ç« ç»“åˆäº§ç”Ÿçš„ideaï¼Œæœ€åä½ æŠŠè¿™ä¸ªideaè¯¦ç»†åŒ–ï¼Œæ¶‰åŠå…¬å¼å’Œç†è®ºè¦è¿›è¡Œæ¨å¯¼ã€‚

{input_text}

è¦æ±‚ï¼š
1. ç›´æ¥è¾“å‡ºè¯¦ç»†åŒ–çš„å†…å®¹ï¼Œä¸è¦å¼€åœºç™½
2. è¯¦ç»†åŒ–åº”åŒ…å«ï¼š
   - ç ”ç©¶èƒŒæ™¯ä¸åŠ¨æœº
   - æ ¸å¿ƒåˆ›æ–°ç‚¹çš„æ·±å…¥é˜è¿°
   - è¯¦ç»†çš„æŠ€æœ¯å®ç°æ–¹æ¡ˆï¼ˆç®—æ³•æ­¥éª¤ã€æ•°å­¦æ¨¡å‹ï¼‰
   - å…¬å¼æ¨å¯¼ï¼ˆæ¶‰åŠçŸ©é˜µå’Œå‘é‡è¯·å…¨éƒ¨å±•å¼€ï¼‰
   - å®éªŒè®¾è®¡ä¸éªŒè¯æ–¹æ¡ˆ
   - é¢„æœŸè´¡çŒ®ä¸å½±å“
   - å¯èƒ½çš„æŒ‘æˆ˜ä¸è§£å†³æ–¹æ¡ˆ
3. ä½¿ç”¨Markdownæ ¼å¼
4. è¡Œé—´å…¬å¼ä¸¤è¾¹ç”¨ä¸¤ä¸ªç¾å…ƒç¬¦å·æ˜¾ç¤ºå…¬å¼ï¼ˆ$$å…¬å¼$$ï¼‰
5. ç¡®ä¿å†…å®¹è¯¦å®ã€é€»è¾‘æ¸…æ™°ã€å¯æ“ä½œæ€§å¼º
"""
        
        system_prompt = "ä½ æ˜¯ç ”ç©¶æ–¹æ¡ˆè¯¦ç»†åŒ–åŠ©æ‰‹ã€‚åŸºäºæä¾›çš„è®ºæ–‡åˆ†æå’Œåˆ›æ–°æƒ³æ³•ï¼Œç”Ÿæˆè¯¦ç»†çš„ç ”ç©¶æ–¹æ¡ˆï¼ŒåŒ…å«å®Œæ•´çš„å…¬å¼æ¨å¯¼ã€‚ç›´æ¥è¾“å‡ºå†…å®¹ï¼Œä¸è¦å®¢å¥—è¯ã€‚"
        
        # æ‰“å°å®Œæ•´çš„è¾“å…¥ä¿¡æ¯
        self.logger.info("=" * 80)
        self.logger.info("ğŸš€ å‡†å¤‡è°ƒç”¨ LLM")
        self.logger.info("=" * 80)
        self.logger.info(f"APIæä¾›å•†: {self.llm_client.api_provider}")
        self.logger.info(f"æ¨¡å‹: {self.llm_client.model}")
        self.logger.info(f"æ¸©åº¦: {self.llm_client.temperature}")
        self.logger.info(f"æœ€å¤§tokens: {self.llm_client.max_tokens}")
        self.logger.info("")
        
        self.logger.info("ğŸ“ System Prompt:")
        self.logger.info("-" * 80)
        self.logger.info(system_prompt)
        self.logger.info("-" * 80)
        self.logger.info("")
        
        self.logger.info("ğŸ“ User Prompt ç»Ÿè®¡:")
        self.logger.info(f"   æ€»å­—ç¬¦æ•°: {len(prompt)}")
        self.logger.info(f"   æ€»è¡Œæ•°: {prompt.count(chr(10))}")
        self.logger.info(f"   ä¼°ç®—tokens: ~{len(prompt) // 2}")  # ç²—ç•¥ä¼°ç®—
        self.logger.info("")
        
        self.logger.info("ğŸ“ User Prompt å®Œæ•´å†…å®¹:")
        self.logger.info("=" * 80)
        self.logger.info(prompt)
        self.logger.info("=" * 80)
        self.logger.info("")
        
        # è°ƒç”¨LLM
        try:
            self.logger.info("â³ æ­£åœ¨è°ƒç”¨ LLM...")
            result = self.llm_client.generate(
                prompt=prompt,
                system_prompt=system_prompt
            )
            
            self.logger.info("=" * 80)
            self.logger.info("âœ… LLM è°ƒç”¨æˆåŠŸ")
            self.logger.info("=" * 80)
            self.logger.info(f"å“åº”é•¿åº¦: {len(result)} å­—ç¬¦")
            self.logger.info(f"å“åº”é¢„è§ˆï¼ˆå‰500å­—ç¬¦ï¼‰:")
            self.logger.info("-" * 80)
            self.logger.info(result[:500])
            self.logger.info("-" * 80)
            self.logger.info("")
            
            return result
            
        except Exception as e:
            self.logger.error("=" * 80)
            self.logger.error("âŒ LLM è°ƒç”¨å¤±è´¥")
            self.logger.error("=" * 80)
            self.log_error(f"é”™è¯¯ä¿¡æ¯: {str(e)}")
            self.logger.error("")
            raise

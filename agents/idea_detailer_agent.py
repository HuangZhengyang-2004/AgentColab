"""
æƒ³æ³•è¯¦ç»†åŒ–Agent
è´Ÿè´£å°†æœ€ä¼˜æƒ³æ³•ç»“åˆç›¸å…³è®ºæ–‡è¿›è¡Œè¯¦ç»†åŒ–
"""

from typing import Dict, Optional, List
import json
from pathlib import Path

from agents.base_agent import BaseAgent
from agents.idea_selector_agent import IdeaSelectorAgent
from utils.api_client import UnifiedLLMClient


class IdeaDetailerAgent(BaseAgent):
    """æƒ³æ³•è¯¦ç»†åŒ–Agent - å¯é…ç½®ä½¿ç”¨ä¸åŒçš„LLM"""
    
    def __init__(self, api_provider: str = None, model: str = None):
        """
        åˆå§‹åŒ–æƒ³æ³•è¯¦ç»†åŒ–Agent
        
        Args:
            api_provider: APIæä¾›å•†ï¼ŒNoneåˆ™ä»é…ç½®è¯»å–
            model: æ¨¡å‹åç§°ï¼ŒNoneåˆ™ä»é…ç½®è¯»å–
        """
        super().__init__("æƒ³æ³•è¯¦ç»†åŒ–Agent")
        
        # ä»é…ç½®è¯»å–APIè®¾ç½®
        if api_provider is None:
            api_provider = self.config_loader.get('pipeline.idea_detailing.api_provider', 'deepseek')
        if model is None:
            model = self.config_loader.get('pipeline.idea_detailing.model', 'deepseek-chat')
        
        temperature = self.config_loader.get('pipeline.idea_detailing.temperature', 0.7)
        max_tokens = self.config_loader.get('pipeline.idea_detailing.max_tokens', 8192)
        
        self.llm_client = UnifiedLLMClient(
            api_provider=api_provider,
            model=model,
            temperature=temperature,
            max_tokens=max_tokens
        )
        
        self.logger.info(f"ä½¿ç”¨ {api_provider} API, æ¨¡å‹: {model}")
        
        # åˆå§‹åŒ–ç­›é€‰Agent
        self.selector = IdeaSelectorAgent()
    
    def run(self, best_idea: Dict = None, source_papers: Dict = None) -> str:
        """
        è¯¦ç»†åŒ–æœ€ä¼˜æƒ³æ³•
        
        Args:
            best_idea: æœ€ä¼˜æƒ³æ³•ä¿¡æ¯ï¼ŒNoneåˆ™è‡ªåŠ¨ç­›é€‰
            source_papers: ç›¸å…³è®ºæ–‡å†…å®¹ï¼ŒNoneåˆ™è‡ªåŠ¨åŠ è½½
            
        Returns:
            è¯¦ç»†åŒ–åçš„æƒ³æ³•æ–‡æœ¬
        """
        self.log_start("è¯¦ç»†åŒ–æƒ³æ³•")
        
        try:
            # å¦‚æœæœªæä¾›æœ€ä¼˜æƒ³æ³•ï¼Œåˆ™è‡ªåŠ¨ç­›é€‰
            if best_idea is None:
                self.logger.info("è‡ªåŠ¨ç­›é€‰æœ€ä¼˜æƒ³æ³•...")
                best_idea = self.selector.run()
            
            if not best_idea:
                self.logger.warning("æœªæ‰¾åˆ°æœ€ä¼˜æƒ³æ³•")
                return ""
            
            # å¦‚æœæœªæä¾›ç›¸å…³è®ºæ–‡ï¼Œåˆ™è‡ªåŠ¨åŠ è½½ï¼ˆä½¿ç”¨åˆ†æå†…å®¹ï¼‰
            if source_papers is None:
                paper_keys = best_idea.get('source_papers', [])
                self.logger.info(f"åŠ è½½ç›¸å…³è®ºæ–‡çš„åˆ†æ: {paper_keys}")
                source_papers = self._get_source_papers_analysis(paper_keys)
            
            if not source_papers:
                self.logger.warning("æœªæ‰¾åˆ°ç›¸å…³è®ºæ–‡")
                return ""
            
            # è°ƒç”¨LLMè¯¦ç»†åŒ–ï¼ˆåˆ†æ­¥è¾“å…¥ï¼‰
            self.logger.info("æ­£åœ¨è¯¦ç»†åŒ–æƒ³æ³•ï¼ˆåˆ†æ­¥è¾“å…¥æ¨¡å¼ï¼‰...")
            detailed_idea = self._detail_idea(source_papers, best_idea, len(source_papers))
            
            # ä¿å­˜ç»“æœ
            self.save_result(
                detailed_idea,
                'detailed_idea.md',
                'ideas',
                format='text'
            )
            
            # åŒæ—¶ä¿å­˜JSONæ ¼å¼ï¼ˆåŒ…å«å…ƒæ•°æ®ï¼‰
            result_data = {
                'original_idea': best_idea,
                'source_papers': list(source_papers.keys()),
                'detailed_content': detailed_idea
            }
            self.save_result(
                result_data,
                'detailed_idea.json',
                'ideas',
                format='json'
            )
            
            self.log_end("æƒ³æ³•è¯¦ç»†åŒ–å®Œæˆ")
            return detailed_idea
            
        except Exception as e:
            self.log_error(f"è¯¦ç»†åŒ–æƒ³æ³•å¤±è´¥: {str(e)}")
            raise
    
    def _get_source_papers_analysis(self, paper_keys: List[str]) -> Dict[str, dict]:
        """
        è·å–æŒ‡å®šè®ºæ–‡çš„åˆ†æå†…å®¹ï¼ˆè€Œä¸æ˜¯æ¸…æ´—åçš„å†…å®¹ï¼‰
        
        Args:
            paper_keys: ['paper_1', 'paper_2', ...]
            
        Returns:
            {
                'paper_1': {'name': ..., 'analysis': ...},
                'paper_2': {'name': ..., 'analysis': ...},
                ...
            }
        """
        collection_path = Path("data/collections/all_papers_analyzed.json")
        
        if not collection_path.exists():
            self.logger.warning(f"æœªæ‰¾åˆ°åˆ†æé›†åˆ: {collection_path}")
            return {}
        
        try:
            with open(collection_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            papers = data.get('papers', {})
            
            # æå–æŒ‡å®šçš„è®ºæ–‡
            result = {}
            for paper_key in paper_keys:
                if paper_key in papers:
                    result[paper_key] = {
                        'name': papers[paper_key].get('name', paper_key),
                        'analysis': papers[paper_key].get('analysis', '')
                    }
                    self.logger.info(f"åŠ è½½è®ºæ–‡åˆ†æ: {paper_key} ({result[paper_key]['name']})")
                else:
                    self.logger.warning(f"æœªæ‰¾åˆ°è®ºæ–‡: {paper_key}")
            
            return result
            
        except Exception as e:
            self.log_error(f"åŠ è½½è®ºæ–‡åˆ†æå¤±è´¥: {str(e)}")
            return {}
    
    def _format_input_for_llm(self, source_papers: Dict[str, dict], best_idea: Dict) -> str:
        """
        æ ¼å¼åŒ–è¾“å…¥ç»™LLM
        
        æ ¼å¼:
        ã€Paper_1ã€‘è®ºæ–‡å1ï¼šåˆ†æå†…å®¹...
        ã€Paper_2ã€‘è®ºæ–‡å2ï¼šåˆ†æå†…å®¹...
        ã€Paper_3ã€‘è®ºæ–‡å3ï¼šåˆ†æå†…å®¹...
        
        ã€åŸºäºä»¥ä¸Šæ–‡ç« çš„åˆ›æ–°æƒ³æ³•ã€‘
        æƒ³æ³•å†…å®¹...
        
        Args:
            source_papers: {paper_key: {'name': ..., 'analysis': ...}}
            best_idea: æœ€ä¼˜æƒ³æ³•ä¿¡æ¯
            
        Returns:
            æ ¼å¼åŒ–çš„æ–‡æœ¬
        """
        self.logger.info("=" * 80)
        self.logger.info("ğŸ“ å¼€å§‹æ ¼å¼åŒ–è¾“å…¥ç»™LLM")
        self.logger.info("=" * 80)
        
        formatted_text = ""
        
        # æŒ‰paper_keyæ’åº
        sorted_keys = sorted(source_papers.keys(), 
                           key=lambda x: int(x.split('_')[1]) if '_' in x else 0)
        
        self.logger.info(f"ğŸ“š è®ºæ–‡æ•°é‡: {len(sorted_keys)}")
        self.logger.info(f"ğŸ“š è®ºæ–‡åˆ—è¡¨: {sorted_keys}")
        self.logger.info("")
        
        # æ·»åŠ è®ºæ–‡åˆ†æå†…å®¹ï¼ˆæŒ‰ã€Paper_iã€‘æ ¼å¼ï¼‰
        for paper_key in sorted_keys:
            paper_data = source_papers[paper_key]
            name = paper_data.get('name', paper_key)
            analysis = paper_data.get('analysis', '')
            
            # æå–paperç¼–å·
            paper_num = paper_key.split('_')[1] if '_' in paper_key else '1'
            
            self.logger.info(f"ğŸ“„ æ·»åŠ  Paper_{paper_num}: {name}")
            self.logger.info(f"   åˆ†æå†…å®¹é•¿åº¦: {len(analysis)} å­—ç¬¦")
            self.logger.info(f"   åˆ†æå†…å®¹é¢„è§ˆ: {analysis[:200]}...")
            self.logger.info("")
            
            formatted_text += f"ã€Paper_{paper_num}ã€‘{name}ï¼š\n\n{analysis}\n\n"
            formatted_text += "=" * 80 + "\n\n"
        
        # æ·»åŠ æƒ³æ³•
        idea_content = best_idea.get('full_content', '')
        self.logger.info("ğŸ’¡ æ·»åŠ æœ€ä¼˜æƒ³æ³•")
        self.logger.info(f"   æƒ³æ³•æ ‡é¢˜: {best_idea.get('title', 'N/A')}")
        self.logger.info(f"   æƒ³æ³•è¯„åˆ†: {best_idea.get('score', 'N/A')}")
        self.logger.info(f"   æƒ³æ³•å†…å®¹é•¿åº¦: {len(idea_content)} å­—ç¬¦")
        self.logger.info(f"   æƒ³æ³•å†…å®¹é¢„è§ˆ: {idea_content[:200]}...")
        self.logger.info("")
        
        formatted_text += "ã€åŸºäºä»¥ä¸Šæ–‡ç« çš„åˆ›æ–°æƒ³æ³•ã€‘\n\n"
        formatted_text += idea_content
        
        self.logger.info("=" * 80)
        self.logger.info("ğŸ“Š æ ¼å¼åŒ–å®Œæˆç»Ÿè®¡")
        self.logger.info("=" * 80)
        self.logger.info(f"æ€»å­—ç¬¦æ•°: {len(formatted_text)}")
        self.logger.info(f"æ€»è¡Œæ•°: {formatted_text.count(chr(10))}")
        self.logger.info("")
        self.logger.info("ğŸ“‹ å®Œæ•´è¾“å…¥å†…å®¹é¢„è§ˆï¼ˆå‰500å­—ç¬¦ï¼‰:")
        self.logger.info("-" * 80)
        self.logger.info(formatted_text[:500])
        self.logger.info("-" * 80)
        self.logger.info("")
        
        return formatted_text
    
    def _detail_idea(self, formatted_papers: Dict[str, dict], best_idea: Dict, n_papers: int) -> str:
        """
        è°ƒç”¨LLMè¯¦ç»†åŒ–æƒ³æ³•ï¼ˆåˆ†æ­¥è¾“å…¥ï¼‰
        
        Args:
            formatted_papers: {paper_key: {'name': ..., 'analysis': ...}}
            best_idea: æœ€ä¼˜æƒ³æ³•ä¿¡æ¯
            n_papers: è®ºæ–‡æ•°é‡
            
        Returns:
            è¯¦ç»†åŒ–åçš„æƒ³æ³•
        """
        self.logger.info("=" * 80)
        self.logger.info("ğŸš€ å‡†å¤‡åˆ†æ­¥è°ƒç”¨ LLM")
        self.logger.info("=" * 80)
        self.logger.info(f"APIæä¾›å•†: {self.llm_client.api_provider}")
        self.logger.info(f"æ¨¡å‹: {self.llm_client.model}")
        self.logger.info(f"æ¸©åº¦: {self.llm_client.temperature}")
        self.logger.info(f"æœ€å¤§tokens: {self.llm_client.max_tokens}")
        self.logger.info(f"è¾“å…¥æ–¹å¼: åˆ†æ­¥è¾“å…¥ï¼ˆå¤šè½®å¯¹è¯ï¼‰")
        self.logger.info("")
        
        system_prompt = "ä½ æ˜¯ç ”ç©¶æ–¹æ¡ˆè¯¦ç»†åŒ–åŠ©æ‰‹ã€‚æˆ‘ä¼šåˆ†æ­¥ç»™ä½ æä¾›è®ºæ–‡åˆ†æå’Œåˆ›æ–°æƒ³æ³•ï¼Œè¯·è®°ä½æ‰€æœ‰å†…å®¹ï¼Œæœ€åæ ¹æ®æˆ‘çš„è¦æ±‚ç”Ÿæˆè¯¦ç»†çš„ç ”ç©¶æ–¹æ¡ˆã€‚"
        
        try:
            # æ­¥éª¤1: ä»»åŠ¡è¯´æ˜
            self.logger.info("=" * 80)
            self.logger.info("ğŸ“ æ­¥éª¤1: å‘é€ä»»åŠ¡è¯´æ˜")
            self.logger.info("=" * 80)
            
            task_prompt = f"""æˆ‘å…ˆç»™ä½ {n_papers}ç¯‡æ–‡ç« çš„åˆ†æå†…å®¹ï¼Œç„¶åå†ç»™ä½ æ ¹æ®è¿™{n_papers}ç¯‡æ–‡ç« ç»“åˆäº§ç”Ÿçš„åˆ›æ–°æƒ³æ³•ï¼Œæœ€åä½ æŠŠè¿™ä¸ªæƒ³æ³•è¯¦ç»†åŒ–ï¼Œæ¶‰åŠå…¬å¼å’Œç†è®ºè¦è¿›è¡Œæ¨å¯¼ã€‚

ç°åœ¨å¼€å§‹ï¼Œæˆ‘ä¼šåˆ†{n_papers + 1}æ­¥ç»™ä½ å†…å®¹ï¼š
- ç¬¬1-{n_papers}æ­¥ï¼šé€ç¯‡ç»™ä½ è®ºæ–‡åˆ†æ
- ç¬¬{n_papers + 1}æ­¥ï¼šç»™ä½ åˆ›æ–°æƒ³æ³•å¹¶è¦æ±‚è¯¦ç»†åŒ–

è¯·å…ˆå›å¤"å¥½çš„ï¼Œæˆ‘å‡†å¤‡å¥½äº†ï¼Œè¯·å¼€å§‹"ã€‚"""
            
            self.logger.info(f"ä»»åŠ¡è¯´æ˜å†…å®¹:")
            self.logger.info("-" * 80)
            self.logger.info(task_prompt)
            self.logger.info("-" * 80)
            self.logger.info("")
            
            response1 = self.llm_client.generate(
                prompt=task_prompt,
                system_prompt=system_prompt
            )
            
            self.logger.info(f"âœ… LLMå“åº”: {response1[:200]}")
            self.logger.info("")
            
            # æ­¥éª¤2-n+1: é€ç¯‡è¾“å…¥è®ºæ–‡
            sorted_keys = sorted(formatted_papers.keys(), 
                               key=lambda x: int(x.split('_')[1]) if '_' in x else 0)
            
            for step_idx, paper_key in enumerate(sorted_keys, 1):
                # æå–åŸå§‹è®ºæ–‡ç¼–å·ï¼ˆä¿æŒä¸ideaä¸­ä¸€è‡´ï¼‰
                original_paper_num = int(paper_key.split('_')[1]) if '_' in paper_key else step_idx
                
                self.logger.info("=" * 80)
                self.logger.info(f"ğŸ“ æ­¥éª¤{step_idx + 1}: å‘é€ Paper_{original_paper_num}")
                self.logger.info("=" * 80)
                
                paper_data = formatted_papers[paper_key]
                name = paper_data.get('name', paper_key)
                analysis = paper_data.get('analysis', '')
                
                paper_prompt = f"""ã€Paper_{original_paper_num}ã€‘{name}ï¼š

{analysis}

è¯·å›å¤"å·²æ”¶åˆ°Paper_{original_paper_num}"ã€‚"""
                
                self.logger.info(f"è®ºæ–‡Key: {paper_key} â†’ Paper_{original_paper_num}")
                self.logger.info(f"è®ºæ–‡åç§°: {name}")
                self.logger.info(f"åˆ†æå†…å®¹é•¿åº¦: {len(analysis)} å­—ç¬¦")
                self.logger.info(f"åˆ†æå†…å®¹é¢„è§ˆ: {analysis[:200]}...")
                self.logger.info("")
                
                # æ·»åŠ é‡è¯•æœºåˆ¶ï¼ˆé’ˆå¯¹500é”™è¯¯ï¼‰
                max_retries = 3
                retry_delay = 2  # ç§’
                
                for attempt in range(max_retries):
                    try:
                        response = self.llm_client.generate(
                            prompt=paper_prompt,
                            system_prompt=system_prompt
                        )
                        
                        self.logger.info(f"âœ… LLMå“åº”: {response[:200]}")
                        self.logger.info("")
                        break  # æˆåŠŸåˆ™è·³å‡ºé‡è¯•å¾ªç¯
                        
                    except Exception as e:
                        error_msg = str(e)
                        if "500" in error_msg and attempt < max_retries - 1:
                            self.logger.warning(f"âš ï¸  é‡åˆ°500é”™è¯¯ï¼Œ{retry_delay}ç§’åé‡è¯• (ç¬¬{attempt + 1}/{max_retries}æ¬¡)")
                            import time
                            time.sleep(retry_delay)
                            retry_delay *= 2  # æŒ‡æ•°é€€é¿
                        else:
                            raise  # æœ€åä¸€æ¬¡é‡è¯•å¤±è´¥æˆ–é500é”™è¯¯ï¼ŒæŠ›å‡ºå¼‚å¸¸
            
            # æœ€åä¸€æ­¥: è¾“å…¥æƒ³æ³•å¹¶è¦æ±‚è¯¦ç»†åŒ–
            self.logger.info("=" * 80)
            self.logger.info(f"ğŸ“ æ­¥éª¤{n_papers + 2}: å‘é€åˆ›æ–°æƒ³æ³•å¹¶è¦æ±‚è¯¦ç»†åŒ–")
            self.logger.info("=" * 80)
            
            idea_content = best_idea.get('full_content', '')
            
            final_prompt = f"""ã€åŸºäºä»¥ä¸Š{n_papers}ç¯‡æ–‡ç« çš„åˆ›æ–°æƒ³æ³•ã€‘

{idea_content}

ç°åœ¨è¯·ä½ æŠŠè¿™ä¸ªæƒ³æ³•è¯¦ç»†åŒ–ï¼Œè¦æ±‚ï¼š
1. ç›´æ¥è¾“å‡ºè¯¦ç»†åŒ–çš„å†…å®¹ï¼Œä¸è¦å¼€åœºç™½
2. è¯¦ç»†åŒ–åº”åŒ…å«ï¼š
   - ç ”ç©¶èƒŒæ™¯ä¸åŠ¨æœº
   - æ ¸å¿ƒåˆ›æ–°ç‚¹çš„æ·±å…¥é˜è¿°
   - è¯¦ç»†çš„æŠ€æœ¯å®ç°æ–¹æ¡ˆï¼ˆç®—æ³•æ­¥éª¤ã€æ•°å­¦æ¨¡å‹ï¼‰
   - å…¬å¼æ¨å¯¼ï¼ˆæ¶‰åŠçŸ©é˜µå’Œå‘é‡è¯·å…¨éƒ¨å±•å¼€ï¼‰
   - å®éªŒè®¾è®¡ä¸éªŒè¯æ–¹æ¡ˆ
   - é¢„æœŸè´¡çŒ®ä¸å½±å“
   - å¯èƒ½çš„æŒ‘æˆ˜ä¸è§£å†³æ–¹æ¡ˆ
3. ä½¿ç”¨Markdownæ ¼å¼
4. è¡Œé—´å…¬å¼ä¸¤è¾¹ç”¨ä¸¤ä¸ªç¾å…ƒç¬¦å·æ˜¾ç¤ºå…¬å¼ï¼ˆ$$å…¬å¼$$ï¼‰
5. ç¡®ä¿å†…å®¹è¯¦å®ã€é€»è¾‘æ¸…æ™°ã€å¯æ“ä½œæ€§å¼º"""
            
            self.logger.info(f"æƒ³æ³•æ ‡é¢˜: {best_idea.get('title', 'N/A')}")
            self.logger.info(f"æƒ³æ³•è¯„åˆ†: {best_idea.get('score', 'N/A')}")
            self.logger.info(f"æƒ³æ³•å†…å®¹é•¿åº¦: {len(idea_content)} å­—ç¬¦")
            self.logger.info(f"æƒ³æ³•å†…å®¹é¢„è§ˆ: {idea_content[:200]}...")
            self.logger.info("")
            
            # æ·»åŠ é‡è¯•æœºåˆ¶ï¼ˆé’ˆå¯¹500é”™è¯¯ï¼‰
            max_retries = 3
            retry_delay = 2
            
            for attempt in range(max_retries):
                try:
                    self.logger.info(f"â³ æ­£åœ¨è°ƒç”¨ LLM ç”Ÿæˆè¯¦ç»†åŒ–å†…å®¹... (å°è¯• {attempt + 1}/{max_retries})")
                    result = self.llm_client.generate(
                        prompt=final_prompt,
                        system_prompt=system_prompt
                    )
                    break  # æˆåŠŸåˆ™è·³å‡ºé‡è¯•å¾ªç¯
                    
                except Exception as e:
                    error_msg = str(e)
                    if "500" in error_msg and attempt < max_retries - 1:
                        self.logger.warning(f"âš ï¸  é‡åˆ°500é”™è¯¯ï¼Œ{retry_delay}ç§’åé‡è¯•")
                        import time
                        time.sleep(retry_delay)
                        retry_delay *= 2
                    else:
                        raise
            
            self.logger.info("=" * 80)
            self.logger.info("âœ… LLM è¯¦ç»†åŒ–å®Œæˆ")
            self.logger.info("=" * 80)
            self.logger.info(f"å“åº”é•¿åº¦: {len(result)} å­—ç¬¦")
            self.logger.info(f"å“åº”é¢„è§ˆï¼ˆå‰500å­—ç¬¦ï¼‰:")
            self.logger.info("-" * 80)
            self.logger.info(result[:500])
            self.logger.info("-" * 80)
            self.logger.info("")
            
            return result
            
        except Exception as e:
            self.logger.error("=" * 80)
            self.logger.error("âŒ LLM è°ƒç”¨å¤±è´¥")
            self.logger.error("=" * 80)
            self.log_error(f"é”™è¯¯ä¿¡æ¯: {str(e)}")
            self.logger.error("")
            raise

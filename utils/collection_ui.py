"""
è®ºæ–‡é›†åˆç®¡ç†åŠŸèƒ½ - ç”¨äºWeb UI
"""

import json
from pathlib import Path
from typing import Tuple, Dict


def load_collection_info(collection_path: str) -> str:
    """åŠ è½½å¹¶æ˜¾ç¤ºé›†åˆä¿¡æ¯"""
    try:
        if not collection_path or not Path(collection_path).exists():
            return "âŒ è¯·å…ˆæå–PDFæˆ–é€‰æ‹©æœ‰æ•ˆçš„é›†åˆæ–‡ä»¶"
        
        with open(collection_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        papers = data.get('papers', {})
        metadata = data.get('metadata', {})
        
        info = f"ğŸ“š è®ºæ–‡é›†åˆä¿¡æ¯\n"
        info += f"=" * 60 + "\n\n"
        info += f"ğŸ“Š ç»Ÿè®¡:\n"
        info += f"  â€¢ æ€»è®ºæ–‡æ•°: {len(papers)}\n"
        info += f"  â€¢ æ€»å­—ç¬¦æ•°: {sum(p['content_length'] for p in papers.values()):,}\n"
        info += f"  â€¢ åˆ›å»ºæ—¶é—´: {metadata.get('created_at', 'N/A')[:19]}\n\n"
        
        info += f"ğŸ“„ è®ºæ–‡åˆ—è¡¨:\n"
        for key in sorted(papers.keys(), key=lambda x: int(x.split('_')[1])):
            paper = papers[key]
            name = paper['name'][:50] + "..." if len(paper['name']) > 50 else paper['name']
            info += f"  {key}: {name}\n"
            info += f"         ({paper['content_length']:,} å­—ç¬¦)\n"
        
        return info
        
    except Exception as e:
        return f"âŒ åŠ è½½å¤±è´¥: {str(e)}"


def view_paper_content(collection_path: str, paper_key: str) -> str:
    """æŸ¥çœ‹ç‰¹å®šè®ºæ–‡å†…å®¹"""
    try:
        if not collection_path or not Path(collection_path).exists():
            return "âŒ è¯·å…ˆæå–PDFæˆ–é€‰æ‹©æœ‰æ•ˆçš„é›†åˆæ–‡ä»¶"
        
        with open(collection_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        papers = data.get('papers', {})
        
        if paper_key not in papers:
            available = ', '.join(sorted(papers.keys()))
            return f"âŒ è®ºæ–‡ '{paper_key}' ä¸å­˜åœ¨\nå¯ç”¨çš„é”®: {available}"
        
        paper = papers[paper_key]
        
        output = f"ğŸ“„ {paper_key}\n"
        output += f"=" * 60 + "\n\n"
        output += f"åç§°: {paper['name']}\n"
        output += f"é•¿åº¦: {paper['content_length']:,} å­—ç¬¦\n"
        output += f"æ·»åŠ æ—¶é—´: {paper.get('added_at', 'N/A')[:19]}\n\n"
        output += f"å†…å®¹é¢„è§ˆ (å‰1000å­—ç¬¦):\n"
        output += "-" * 60 + "\n"
        output += paper['content'][:1000]
        output += "\n\n..." if len(paper['content']) > 1000 else ""
        
        return output
        
    except Exception as e:
        return f"âŒ é”™è¯¯: {str(e)}"


def export_collection_summary(collection_path: str) -> Tuple[str, str]:
    """å¯¼å‡ºé›†åˆæ‘˜è¦ä¸ºæ–‡æœ¬æ–‡ä»¶"""
    try:
        if not collection_path or not Path(collection_path).exists():
            return "âŒ è¯·å…ˆæå–PDFæˆ–é€‰æ‹©æœ‰æ•ˆçš„é›†åˆæ–‡ä»¶", ""
        
        with open(collection_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        papers = data.get('papers', {})
        metadata = data.get('metadata', {})
        
        # ç”Ÿæˆæ‘˜è¦æ–‡æœ¬
        summary = f"è®ºæ–‡é›†åˆæ‘˜è¦\n"
        summary += f"{'=' * 60}\n\n"
        summary += f"åˆ›å»ºæ—¶é—´: {metadata.get('created_at', 'N/A')}\n"
        summary += f"æ€»è®ºæ–‡æ•°: {len(papers)}\n"
        summary += f"æ€»å­—ç¬¦æ•°: {sum(p['content_length'] for p in papers.values()):,}\n\n"
        
        summary += f"è®ºæ–‡è¯¦æƒ…:\n"
        summary += f"{'-' * 60}\n\n"
        
        for key in sorted(papers.keys(), key=lambda x: int(x.split('_')[1])):
            paper = papers[key]
            summary += f"{key}:\n"
            summary += f"  åç§°: {paper['name']}\n"
            summary += f"  é•¿åº¦: {paper['content_length']:,} å­—ç¬¦\n"
            summary += f"  æ·»åŠ : {paper.get('added_at', 'N/A')[:19]}\n"
            summary += f"  é¢„è§ˆ: {paper['content'][:200]}...\n\n"
        
        # ä¿å­˜æ‘˜è¦
        output_path = collection_path.replace('.json', '_summary.txt')
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(summary)
        
        return f"âœ“ æ‘˜è¦å·²å¯¼å‡ºåˆ°:\n{output_path}\n\n{summary}", output_path
        
    except Exception as e:
        return f"âŒ é”™è¯¯: {str(e)}", ""


def merge_collections(collection_paths: str) -> Tuple[str, str]:
    """åˆå¹¶å¤šä¸ªé›†åˆ"""
    try:
        paths = [p.strip() for p in collection_paths.strip().split('\n') if p.strip()]
        
        if len(paths) < 2:
            return "âŒ è¯·è¾“å…¥è‡³å°‘2ä¸ªé›†åˆè·¯å¾„ï¼ˆæ¯è¡Œä¸€ä¸ªï¼‰", ""
        
        from utils.paper_collection import PaperCollection
        
        # åˆ›å»ºæ–°é›†åˆ
        merged = PaperCollection()
        
        total_loaded = 0
        for path in paths:
            if not Path(path).exists():
                return f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {path}", ""
            
            temp = PaperCollection.load_from_json(path)
            merged.add_papers_batch(temp.get_all_contents())
            total_loaded += len(temp)
        
        # ä¿å­˜åˆå¹¶ç»“æœ
        output_path = "data/collections/merged_collection.json"
        merged.save_to_json(output_path)
        
        report = f"âœ“ åˆå¹¶æˆåŠŸï¼\n\n"
        report += f"åˆå¹¶äº† {len(paths)} ä¸ªé›†åˆ\n"
        report += f"æ€»è®ºæ–‡æ•°: {total_loaded} â†’ {len(merged)}\n"
        report += f"ä¿å­˜ä½ç½®: {output_path}\n"
        
        return report, output_path
        
    except Exception as e:
        return f"âŒ é”™è¯¯: {str(e)}", ""

